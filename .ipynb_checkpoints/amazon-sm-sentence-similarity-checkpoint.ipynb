{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test Sentence Transformer model using SageMaker\n",
    "\n",
    "\n",
    "In this notebook, we fine tune pretrained `bert-base-uncased` model from `HuggingFace Library` in an unsupervised fashion, on `Industrial labor accident data`. The objective is to find the similar accident reports based on the description of the incident using `bert-base-uncased`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Update sagemaker package and restart the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker -q\n",
    "# !pip install sentence_transformers -q\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.214.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, os, sagemaker\n",
    "import json\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() \n",
    "prefix = 'sentencetransformer/input'\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Download the dataset from: https://www.kaggle.com/ihmstefanini/industrial-safety-and-health-analytics-database and upload the downloaded csv file to the notebook. \n",
    "\n",
    "The database is basically records of accidents from 12 different plants in 03 different countries which every line in the data is an occurrence of an accident.\n",
    "\n",
    "**Columns description**\n",
    "- Data: timestamp or time/date information\n",
    "- Countries: which country the accident occurred (anonymized)\n",
    "- Local: the city where the manufacturing plant is located (anonymized)\n",
    "- Industry sector: which sector the plant belongs to\n",
    "- Accident level: from I to VI, it registers how severe was the accident (I means not severe but VI means very severe)\n",
    "- Potential Accident Level: Depending on the Accident Level, the database also registers how severe the accident could have been (due to other factors involved in the accident)\n",
    "- Genre: if the person is male of female\n",
    "- Employee or Third Party: if the injured person is an employee or a third party\n",
    "- Critical Risk: some description of the risk involved in the accident\n",
    "- Description: Detailed description of how the accident happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_data = pd.read_csv('IHMStefanini_industrial_safety_and_health_database_with_accidents_description.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Local</th>\n",
       "      <th>Industry Sector</th>\n",
       "      <th>Accident Level</th>\n",
       "      <th>Potential Accident Level</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Employee or Third Party</th>\n",
       "      <th>Critical Risk</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_01</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Pressed</td>\n",
       "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02 00:00:00</td>\n",
       "      <td>Country_02</td>\n",
       "      <td>Local_02</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Employee</td>\n",
       "      <td>Pressurized Systems</td>\n",
       "      <td>During the activation of a sodium sulphide pum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_03</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>III</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party (Remote)</td>\n",
       "      <td>Manual Tools</td>\n",
       "      <td>In the sub-station MILPO located at level +170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_04</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Others</td>\n",
       "      <td>Being 9:45 am. approximately in the Nv. 1880 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-10 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_04</td>\n",
       "      <td>Mining</td>\n",
       "      <td>IV</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Others</td>\n",
       "      <td>Approximately at 11:45 a.m. in circumstances t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Data   Countries     Local Industry Sector Accident Level  \\\n",
       "0  2016-01-01 00:00:00  Country_01  Local_01          Mining              I   \n",
       "1  2016-01-02 00:00:00  Country_02  Local_02          Mining              I   \n",
       "2  2016-01-06 00:00:00  Country_01  Local_03          Mining              I   \n",
       "3  2016-01-08 00:00:00  Country_01  Local_04          Mining              I   \n",
       "4  2016-01-10 00:00:00  Country_01  Local_04          Mining             IV   \n",
       "\n",
       "  Potential Accident Level Genre Employee or Third Party        Critical Risk  \\\n",
       "0                       IV  Male             Third Party              Pressed   \n",
       "1                       IV  Male                Employee  Pressurized Systems   \n",
       "2                      III  Male    Third Party (Remote)         Manual Tools   \n",
       "3                        I  Male             Third Party               Others   \n",
       "4                       IV  Male             Third Party               Others   \n",
       "\n",
       "                                         Description  \n",
       "0  While removing the drill rod of the Jumbo 08 f...  \n",
       "1  During the activation of a sodium sulphide pum...  \n",
       "2  In the sub-station MILPO located at level +170...  \n",
       "3  Being 9:45 am. approximately in the Nv. 1880 C...  \n",
       "4  Approximately at 11:45 a.m. in circumstances t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data['Industry Sector'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data['Genre'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-827930657850/sentencetransformer/input/train.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train.csv')).upload_file('IHMStefanini_industrial_safety_and_health_database_with_accidents_description.csv')\n",
    "training_input_path = \"s3://{}/{}/train.csv\".format(bucket,prefix)\n",
    "training_input_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning UnSupervised Sentence Transformer on your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 8,\n",
    "                 'model_name':'bert-base-uncased'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, including the following:\n",
    "\n",
    "- **SM_MODEL_DIR**: A string that represents the path where the training job writes the model artifacts to. After training, artifacts in this directory are uploaded to S3 for model hosting. SM_MODEL_DIR is always set to /opt/ml/model.\n",
    "\n",
    "- **SM_NUM_GPUS**: An integer representing the number of GPUs available to the host.\n",
    "\n",
    "- **SM_CHANNEL_XXXX**: A string that represents the path to the directory that contains the input data for the specified channel. For example, if you specify two input channels in the HuggingFace estimator’s fit call, named train and test, the environment variables SM_CHANNEL_TRAIN and SM_CHANNEL_TEST are set.\n",
    "\n",
    "You can find a full list of the exposed environment variables [here](#https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md).\n",
    "\n",
    "Later we define hyperparameters in the HuggingFace Estimator, which are passed in as named arguments and and can be processed with the [ArgumentParser()](#https://huggingface.co/docs/sagemaker/train#create-an-huggingface-estimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msentence_transformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SentenceTransformer, LoggingHandler\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msentence_transformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m models, util, datasets, evaluation, losses\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mipywidgets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m widgets\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnltk\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "nltk.download(\u001b[33m'\u001b[39;49;00m\u001b[33mpunkt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m16\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--warmup_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m500\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34m5e-5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--training_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    args, _ = parser.parse_known_args()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Set up logging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logging.basicConfig(\u001b[37m\u001b[39;49;00m\n",
      "        level=logging.getLevelName(\u001b[33m\"\u001b[39;49;00m\u001b[33mINFO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        handlers=[logging.StreamHandler(sys.stdout)],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(name)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    word_embedding_model = models.Transformer(args.model_name)\u001b[37m\u001b[39;49;00m\n",
      "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\u001b[37m\u001b[39;49;00m\n",
      "                                   pooling_mode_mean_tokens=\u001b[34mFalse\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "                                   pooling_mode_cls_token = \u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# read data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m******* list files *********: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, os.listdir(args.training_dir))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m********************** Reading Data *************************\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    df_data = pd.read_csv(os.path.join(args.training_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), index_col=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(df_data.head(\u001b[34m5\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    train_sentences = df_data[\u001b[33m'\u001b[39;49;00m\u001b[33mDescription\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].tolist()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    train_dataset = datasets.DenoisingAutoEncoderDataset(train_sentences)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train_dataloader = DataLoader(train_dataset, batch_size=args.train_batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#use the denoising auto-encoder loss\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_loss = losses.DenoisingAutoEncoderLoss(model, decoder_name_or_path=args.model_name, tie_encoder_decoder=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#call the fit method\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model.fit(train_objectives=[(train_dataloader, train_loss)],\u001b[37m\u001b[39;49;00m\n",
      "             epochs = args.epochs, \u001b[37m\u001b[39;49;00m\n",
      "             weight_decay=\u001b[34m0\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "             scheduler=\u001b[33m'\u001b[39;49;00m\u001b[33mconstantlr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "             optimizer_params={\u001b[33m'\u001b[39;49;00m\u001b[33mlr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.learning_rate}, \u001b[37m\u001b[39;49;00m\n",
      "             )\u001b[37m\u001b[39;49;00m\n",
      "    model.save(args.model_dir)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./code/unsupervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='unsupervised.py',\n",
    "                            source_dir='./code',\n",
    "                            instance_type='ml.p3.2xlarge', # GPU supported by Hugging Face\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            transformers_version='4.6',\n",
    "                            pytorch_version='1.7',\n",
    "                            py_version='py36',\n",
    "                            hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-04-10-15-26-32-233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:26:32 Starting - Starting the training job...\n",
      "2024-04-10 15:26:45 Pending - Training job waiting for capacity...\n",
      "2024-04-10 15:27:20 Pending - Preparing the instances for training...\n",
      "2024-04-10 15:27:58 Downloading - Downloading the training image...............\n",
      "2024-04-10 15:30:19 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-04-10 15:30:43,666 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-04-10 15:30:43,698 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-04-10 15:30:43,700 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-04-10 15:30:43,909 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\u001b[0m\n",
      "\u001b[34mCollecting ipywidgets\n",
      "  Downloading ipywidgets-7.8.1-py2.py3-none-any.whl (124 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.17.79)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (4.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (4.49.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.5.4)\u001b[0m\n",
      "\u001b[34mCollecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.1.91)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (4.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (3.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (20.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->-r requirements.txt (line 1)) (0.10.3)\u001b[0m\n",
      "\u001b[34mCollecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->-r requirements.txt (line 1)) (0.0.45)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->-r requirements.txt (line 1)) (2021.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets->-r requirements.txt (line 2)) (7.16.1)\u001b[0m\n",
      "\u001b[34mCollecting widgetsnbextension~=3.6.6\n",
      "  Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets->-r requirements.txt (line 2)) (4.3.3)\u001b[0m\n",
      "\u001b[34mCollecting jupyterlab-widgets<3,>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.1.7-py3-none-any.whl (295 kB)\u001b[0m\n",
      "\u001b[34mCollecting comm>=0.1.3\n",
      "  Downloading comm-0.1.4-py3-none-any.whl (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (2.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (3.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (4.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (0.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 2)) (0.2.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting notebook>=4.4.1\n",
      "  Downloading notebook-6.4.10-py3-none-any.whl (9.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (22.0.3)\u001b[0m\n",
      "\u001b[34mCollecting nbconvert>=5\n",
      "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (3.0.1)\u001b[0m\n",
      "\u001b[34mCollecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting Send2Trash>=1.8.0\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-core>=4.6.1\n",
      "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-client>=5.3.4\n",
      "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\u001b[0m\n",
      "\u001b[34mCollecting nbformat\n",
      "  Downloading nbformat-5.1.3-py3-none-any.whl (178 kB)\u001b[0m\n",
      "\u001b[34mCollecting nest-asyncio>=1.5\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-client\n",
      "  Downloading prometheus_client-0.17.1-py3-none-any.whl (60 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (6.1)\u001b[0m\n",
      "\u001b[34mCollecting ipykernel\n",
      "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\u001b[0m\n",
      "\u001b[34mCollecting terminado>=0.8.3\n",
      "  Downloading terminado-0.12.1-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client>=5.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mCollecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.9-py3-none-any.whl (69 kB)\u001b[0m\n",
      "\u001b[34mCollecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting bleach\n",
      "  Downloading bleach-4.1.0-py2.py3-none-any.whl (157 kB)\u001b[0m\n",
      "\u001b[34mCollecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting testpath\n",
      "  Downloading testpath-0.6.0-py3-none-any.whl (83 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting async-generator\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema!=2.5.0,>=2.4\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (0.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 3)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from boto3->-r requirements.txt (line 4)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->-r requirements.txt (line 4)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.21.0,>=1.20.79 in /opt/conda/lib/python3.6/site-packages (from boto3->-r requirements.txt (line 4)) (1.20.79)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.79->boto3->-r requirements.txt (line 4)) (1.25.11)\u001b[0m\n",
      "\u001b[34mCollecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (1.14.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets->-r requirements.txt (line 2)) (2.20)\u001b[0m\n",
      "\u001b[34mCollecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk->sentence-transformers->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk->sentence-transformers->-r requirements.txt (line 1)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 1)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision->sentence-transformers->-r requirements.txt (line 1)) (8.2.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125919 sha256=561084c7ead76402f0ec4ebede4477ced3de6eb90cb850b625b15594cd9c508b\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/90/11/0e58d454669bc8daf94e04a8da9956aa6f78eb10cddb16dd4e\u001b[0m\n",
      "\u001b[34mSuccessfully built sentence-transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyrsistent, nest-asyncio, jupyter-core, jsonschema, entrypoints, webencodings, nbformat, jupyter-client, async-generator, testpath, pandocfilters, nbclient, mistune, jupyterlab-pygments, defusedxml, bleach, argon2-cffi-bindings, terminado, Send2Trash, regex, prometheus-client, nbconvert, ipykernel, argon2-cffi, tokenizers, notebook, huggingface-hub, widgetsnbextension, transformers, nltk, jupyterlab-widgets, comm, sentence-transformers, ipywidgets\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.4.4\n",
      "    Uninstalling regex-2021.4.4:\n",
      "      Successfully uninstalled regex-2021.4.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.8\n",
      "    Uninstalling huggingface-hub-0.0.8:\n",
      "      Successfully uninstalled huggingface-hub-0.0.8\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.6.1\u001b[0m\n",
      "\u001b[34m    Uninstalling transformers-4.6.1:\n",
      "      Successfully uninstalled transformers-4.6.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed Send2Trash-1.8.3 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 async-generator-1.10 bleach-4.1.0 comm-0.1.4 defusedxml-0.7.1 entrypoints-0.4 huggingface-hub-0.4.0 ipykernel-5.5.6 ipywidgets-7.8.1 jsonschema-3.2.0 jupyter-client-7.1.2 jupyter-core-4.9.2 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.1.7 mistune-0.8.4 nbclient-0.5.9 nbconvert-6.0.7 nbformat-5.1.3 nest-asyncio-1.6.0 nltk-3.6.7 notebook-6.4.10 pandocfilters-1.5.1 prometheus-client-0.17.1 pyrsistent-0.18.0 regex-2023.8.8 sentence-transformers-2.2.2 terminado-0.12.1 testpath-0.6.0 tokenizers-0.12.1 transformers-4.18.0 webencodings-0.5.1 widgetsnbextension-3.6.6\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mdatasets 1.6.2 requires huggingface-hub<0.1.0, but you have huggingface-hub 0.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:01,224 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"model_name\": \"bert-base-uncased\",\n",
      "        \"train_batch_size\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-04-10-15-26-32-233\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-827930657850/huggingface-pytorch-training-2024-04-10-15-26-32-233/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"unsupervised\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"unsupervised.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"bert-base-uncased\",\"train_batch_size\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=unsupervised.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=unsupervised\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-827930657850/huggingface-pytorch-training-2024-04-10-15-26-32-233/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"bert-base-uncased\",\"train_batch_size\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2024-04-10-15-26-32-233\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-827930657850/huggingface-pytorch-training-2024-04-10-15-26-32-233/source/sourcedir.tar.gz\",\"module_name\":\"unsupervised\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"unsupervised.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"bert-base-uncased\",\"--train_batch_size\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=bert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 unsupervised.py --epochs 1 --model_name bert-base-uncased --train_batch_size 8\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:04,235 - filelock - INFO - Lock 140099022798240 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:04,266 - filelock - INFO - Lock 140099022798240 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:04,358 - filelock - INFO - Lock 140098970184280 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:13,031 - filelock - INFO - Lock 140098970184280 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:15,020 - filelock - INFO - Lock 140098971173832 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:15,056 - filelock - INFO - Lock 140098971173832 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:15,335 - filelock - INFO - Lock 140098422578144 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:15,579 - filelock - INFO - Lock 140098422578144 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:15,614 - filelock - INFO - Lock 140098422577752 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:15,664 - filelock - INFO - Lock 140098422577752 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:16,524 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cuda\u001b[0m\n",
      "\u001b[34m******* list files *********:  ['train.csv']\u001b[0m\n",
      "\u001b[34m********************** Reading Data *************************\n",
      "                  Data  ...                                        Description\u001b[0m\n",
      "\u001b[34m0  2016-01-01 00:00:00  ...  While removing the drill rod of the Jumbo 08 f...\u001b[0m\n",
      "\u001b[34m1  2016-01-02 00:00:00  ...  During the activation of a sodium sulphide pum...\u001b[0m\n",
      "\u001b[34m2  2016-01-06 00:00:00  ...  In the sub-station MILPO located at level +170...\u001b[0m\n",
      "\u001b[34m3  2016-01-08 00:00:00  ...  Being 9:45 am. approximately in the Nv. 1880 C...\u001b[0m\n",
      "\u001b[34m4  2016-01-10 00:00:00  ...  Approximately at 11:45 a.m. in circumstances t...\u001b[0m\n",
      "\u001b[34m[5 rows x 10 columns]\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:16,568 - sentence_transformers.losses.DenoisingAutoEncoderLoss - WARNING - When tie_encoder_decoder=True, the decoder_name_or_path will be invalid.\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.511 algo-1:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.553 algo-1:39 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.553 algo-1:39 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.554 algo-1:39 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.554 algo-1:39 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.555 algo-1:39 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.661 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.661 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.661 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.embeddings.token_type_embeddings.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.662 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.663 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.664 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.665 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.666 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.667 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.668 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.669 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.670 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.671 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.672 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.673 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.674 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.675 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.676 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.677 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.678 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.679 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.pooler.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.680 algo-1:39 INFO hook.py:591] name:encoder.0.auto_model.pooler.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.681 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.682 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.683 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.684 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.685 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.686 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.687 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.688 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.689 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.690 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.691 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.692 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.cls.predictions.bias count_params:30522\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.cls.predictions.transform.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.693 algo-1:39 INFO hook.py:591] name:decoder.cls.predictions.transform.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.694 algo-1:39 INFO hook.py:591] name:decoder.cls.predictions.transform.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.694 algo-1:39 INFO hook.py:591] name:decoder.cls.predictions.transform.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.694 algo-1:39 INFO hook.py:593] Total Trainable Params: 138471738\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.694 algo-1:39 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-04-10 15:31:22.696 algo-1:39 INFO hook.py:488] Hook is writing from the hook with pid: 39\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:39,563 - sentence_transformers.SentenceTransformer - INFO - Save model to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package punkt to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping tokenizers/punkt.zip.\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 570/570 [00:00<00:00, 700kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]#015Downloading:   1%|          | 4.31M/420M [00:00<00:09, 45.1MB/s]#015Downloading:   2%|▏         | 8.65M/420M [00:00<00:09, 45.3MB/s]#015Downloading:   3%|▎         | 13.1M/420M [00:00<00:09, 45.7MB/s]#015Downloading:   4%|▍         | 17.5M/420M [00:00<00:09, 45.9MB/s]#015Downloading:   5%|▌         | 22.0M/420M [00:00<00:09, 46.2MB/s]#015Downloading:   6%|▋         | 26.6M/420M [00:00<00:08, 46.7MB/s]#015Downloading:   7%|▋         | 31.1M/420M [00:00<00:08, 47.0MB/s]#015Downloading:   9%|▊         | 35.7M/420M [00:00<00:08, 47.3MB/s]#015Downloading:  10%|▉         | 40.4M/420M [00:00<00:08, 47.8MB/s]#015Downloading:  11%|█         | 45.2M/420M [00:01<00:08, 48.6MB/s]#015Downloading:  12%|█▏        | 50.1M/420M [00:01<00:07, 49.4MB/s]#015Downloading:  13%|█▎        | 54.9M/420M [00:01<00:07, 49.7MB/s]#015Downloading:  14%|█▍        | 59.8M/420M [00:01<00:07, 50.1MB/s]#015Downloading:  15%|█▌        | 64.7M/420M [00:01<00:07, 50.4MB/s]#015Downloading:  17%|█▋        | 69.5M/420M [00:01<00:07, 50.6MB/s]#015Downloading:  18%|█▊        | 74.4M/420M [00:01<00:07, 50.6MB/s]#015Downloading:  19%|█▉        | 79.2M/420M [00:01<00:07, 50.8MB/s]#015Downloading:  20%|██        | 84.1M/420M [00:01<00:06, 50.9MB/s]#015Downloading:  21%|██        | 89.0M/420M [00:01<00:06, 50.7MB/s]#015Downloading:  22%|██▏       | 93.9M/420M [00:02<00:06, 50.9MB/s]#015Downloading:  24%|██▎       | 98.8M/420M [00:02<00:06, 51.2MB/s]#015Downloading:  25%|██▍       | 104M/420M [00:02<00:06, 51.4MB/s] #015Downloading:  26%|██▌       | 109M/420M [00:02<00:06, 51.4MB/s]#015Downloading:  27%|██▋       | 114M/420M [00:02<00:06, 51.5MB/s]#015Downloading:  28%|██▊       | 119M/420M [00:02<00:06, 51.6MB/s]#015Downloading:  29%|██▉       | 123M/420M [00:02<00:06, 51.6MB/s]#015Downloading:  31%|███       | 128M/420M [00:02<00:05, 51.6MB/s]#015Downloading:  32%|███▏      | 133M/420M [00:02<00:05, 51.7MB/s]#015Downloading:  33%|███▎      | 138M/420M [00:02<00:05, 51.6MB/s]#015Downloading:  34%|███▍      | 143M/420M [00:03<00:05, 51.6MB/s]#015Downloading:  35%|███▌      | 148M/420M [00:03<00:05, 51.5MB/s]#015Downloading:  36%|███▋      | 153M/420M [00:03<00:05, 51.6MB/s]#015Downloading:  38%|███▊      | 158M/420M [00:03<00:05, 51.8MB/s]#015Downloading:  39%|███▉      | 163M/420M [00:03<00:05, 51.7MB/s]#015Downloading:  40%|███▉      | 168M/420M [00:03<00:05, 51.6MB/s]#015Downloading:  41%|████      | 173M/420M [00:03<00:05, 51.6MB/s]#015Downloading:  42%|████▏     | 178M/420M [00:03<00:04, 51.4MB/s]#015Downloading:  43%|████▎     | 183M/420M [00:03<00:04, 51.5MB/s]#015Downloading:  45%|████▍     | 188M/420M [00:03<00:04, 51.4MB/s]#015Downloading:  46%|████▌     | 192M/420M [00:04<00:04, 51.4MB/s]#015Downloading:  47%|████▋     | 197M/420M [00:04<00:04, 51.5MB/s]#015Downloading:  48%|████▊     | 202M/420M [00:04<00:04, 51.5MB/s]#015Downloading:  49%|████▉     | 207M/420M [00:04<00:04, 51.6MB/s]#015Downloading:  51%|█████     | 212M/420M [00:04<00:04, 51.6MB/s]#015Downloading:  52%|█████▏    | 217M/420M [00:04<00:04, 51.6MB/s]#015Downloading:  53%|█████▎    | 222M/420M [00:04<00:04, 51.7MB/s]#015Downloading:  54%|█████▍    | 227M/420M [00:04<00:03, 51.7MB/s]#015Downloading:  55%|█████▌    | 232M/420M [00:04<00:03, 51.6MB/s]#015Downloading:  56%|█████▋    | 237M/420M [00:04<00:03, 51.6MB/s]#015Downloading:  58%|█████▊    | 242M/420M [00:05<00:03, 51.6MB/s]#015Downloading:  59%|█████▊    | 247M/420M [00:05<00:03, 51.7MB/s]#015Downloading:  60%|█████▉    | 252M/420M [00:05<00:03, 51.7MB/s]#015Downloading:  61%|██████    | 257M/420M [00:05<00:03, 51.6MB/s]#015Downloading:  62%|██████▏   | 262M/420M [00:05<00:03, 51.6MB/s]#015Downloading:  63%|██████▎   | 266M/420M [00:05<00:03, 51.6MB/s]#015Downloading:  65%|██████▍   | 271M/420M [00:05<00:03, 51.6MB/s]#015Downloading:  66%|██████▌   | 276M/420M [00:05<00:02, 51.5MB/s]#015Downloading:  67%|██████▋   | 281M/420M [00:05<00:02, 51.5MB/s]#015Downloading:  68%|██████▊   | 286M/420M [00:05<00:02, 51.5MB/s]#015Downloading:  69%|██████▉   | 291M/420M [00:06<00:02, 51.3MB/s]#015Downloading:  70%|███████   | 296M/420M [00:06<00:02, 51.3MB/s]#015Downloading:  72%|███████▏  | 301M/420M [00:06<00:02, 51.2MB/s]#015Downloading:  73%|███████▎  | 306M/420M [00:06<00:02, 51.2MB/s]#015Downloading:  74%|███████▍  | 311M/420M [00:06<00:02, 51.2MB/s]#015Downloading:  75%|███████▌  | 316M/420M [00:06<00:02, 51.3MB/s]#015Downloading:  76%|███████▋  | 320M/420M [00:06<00:02, 51.3MB/s]#015Downloading:  77%|███████▋  | 325M/420M [00:06<00:01, 51.4MB/s]#015Downloading:  79%|███████▊  | 330M/420M [00:06<00:01, 51.3MB/s]#015Downloading:  80%|███████▉  | 335M/420M [00:06<00:01, 51.3MB/s]#015Downloading:  81%|████████  | 340M/420M [00:07<00:01, 51.2MB/s]#015Downloading:  82%|████████▏ | 345M/420M [00:07<00:01, 51.2MB/s]#015Downloading:  83%|████████▎ | 350M/420M [00:07<00:01, 51.1MB/s]#015Downloading:  84%|████████▍ | 355M/420M [00:07<00:01, 51.0MB/s]#015Downloading:  86%|████████▌ | 360M/420M [00:07<00:01, 51.2MB/s]#015Downloading:  87%|████████▋ | 364M/420M [00:07<00:01, 51.0MB/s]#015Downloading:  88%|████████▊ | 369M/420M [00:07<00:01, 51.1MB/s]#015Downloading:  89%|████████▉ | 374M/420M [00:07<00:00, 51.2MB/s]#015Downloading:  90%|█████████ | 379M/420M [00:07<00:00, 51.3MB/s]#015Downloading:  91%|█████████▏| 384M/420M [00:07<00:00, 51.2MB/s]#015Downloading:  93%|█████████▎| 389M/420M [00:08<00:00, 51.2MB/s]#015Downloading:  94%|█████████▍| 394M/420M [00:08<00:00, 51.3MB/s]#015Downloading:  95%|█████████▍| 399M/420M [00:08<00:00, 51.4MB/s]#015Downloading:  96%|█████████▌| 404M/420M [00:08<00:00, 51.5MB/s]#015Downloading:  97%|█████████▋| 409M/420M [00:08<00:00, 51.4MB/s]#015Downloading:  98%|█████████▊| 414M/420M [00:08<00:00, 51.5MB/s]#015Downloading: 100%|█████████▉| 418M/420M [00:08<00:00, 51.6MB/s]#015Downloading: 100%|██████████| 420M/420M [00:08<00:00, 50.9MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 49.8kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]#015Downloading: 100%|█████████▉| 225k/226k [00:00<00:00, 2.10MB/s]#015Downloading: 100%|██████████| 226k/226k [00:00<00:00, 2.09MB/s]\u001b[0m\n",
      "\u001b[34m2024-04-10 15:31:40,909 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 455k/455k [00:00<00:00, 46.2MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.value.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mThe following encoder weights were not tied to the decoder ['bert/pooler']\u001b[0m\n",
      "\u001b[34m#015Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#015Iteration:   0%|          | 0/54 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:   2%|▏         | 1/54 [00:01<01:11,  1.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:   4%|▎         | 2/54 [00:01<01:07,  1.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:   6%|▌         | 3/54 [00:01<01:03,  1.25s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:   7%|▋         | 4/54 [00:02<01:00,  1.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:   9%|▉         | 5/54 [00:02<00:56,  1.16s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  11%|█         | 6/54 [00:02<00:53,  1.12s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  13%|█▎        | 7/54 [00:03<00:50,  1.07s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  15%|█▍        | 8/54 [00:03<00:47,  1.04s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  17%|█▋        | 9/54 [00:03<00:44,  1.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  19%|█▊        | 10/54 [00:04<00:42,  1.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  20%|██        | 11/54 [00:04<00:39,  1.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  22%|██▏       | 12/54 [00:04<00:37,  1.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  24%|██▍       | 13/54 [00:04<00:35,  1.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  26%|██▌       | 14/54 [00:05<00:33,  1.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  28%|██▊       | 15/54 [00:05<00:31,  1.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  30%|██▉       | 16/54 [00:05<00:29,  1.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  31%|███▏      | 17/54 [00:06<00:28,  1.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  33%|███▎      | 18/54 [00:06<00:26,  1.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  35%|███▌      | 19/54 [00:06<00:25,  1.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  37%|███▋      | 20/54 [00:07<00:23,  1.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  39%|███▉      | 21/54 [00:07<00:22,  1.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  41%|████      | 22/54 [00:07<00:21,  1.52it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  43%|████▎     | 23/54 [00:07<00:19,  1.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  44%|████▍     | 24/54 [00:08<00:18,  1.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  46%|████▋     | 25/54 [00:08<00:17,  1.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  48%|████▊     | 26/54 [00:08<00:16,  1.68it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  50%|█████     | 27/54 [00:09<00:15,  1.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  52%|█████▏    | 28/54 [00:09<00:14,  1.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  54%|█████▎    | 29/54 [00:09<00:13,  1.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  56%|█████▌    | 30/54 [00:10<00:12,  1.86it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  57%|█████▋    | 31/54 [00:10<00:12,  1.91it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  59%|█████▉    | 32/54 [00:10<00:11,  1.95it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  61%|██████    | 33/54 [00:10<00:10,  2.00it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  63%|██████▎   | 34/54 [00:11<00:09,  2.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  65%|██████▍   | 35/54 [00:11<00:09,  2.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  67%|██████▋   | 36/54 [00:11<00:08,  2.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  69%|██████▊   | 37/54 [00:12<00:07,  2.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  70%|███████   | 38/54 [00:12<00:07,  2.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  72%|███████▏  | 39/54 [00:12<00:06,  2.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  74%|███████▍  | 40/54 [00:12<00:06,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  76%|███████▌  | 41/54 [00:13<00:05,  2.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  78%|███████▊  | 42/54 [00:13<00:05,  2.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  80%|███████▉  | 43/54 [00:13<00:04,  2.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  81%|████████▏ | 44/54 [00:14<00:04,  2.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  83%|████████▎ | 45/54 [00:14<00:03,  2.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  85%|████████▌ | 46/54 [00:14<00:03,  2.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  87%|████████▋ | 47/54 [00:15<00:02,  2.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  89%|████████▉ | 48/54 [00:15<00:02,  2.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  91%|█████████ | 49/54 [00:15<00:01,  2.61it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  93%|█████████▎| 50/54 [00:15<00:01,  2.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  94%|█████████▍| 51/54 [00:16<00:01,  2.69it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  96%|█████████▋| 52/54 [00:16<00:00,  2.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration:  98%|█████████▊| 53/54 [00:16<00:00,  2.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Iteration: 100%|██████████| 54/54 [00:16<00:00,  2.77it/s]#033[A#015Iteration: 100%|██████████| 54/54 [00:16<00:00,  3.18it/s]\u001b[0m\n",
      "\u001b[34m#015Epoch: 100%|██████████| 1/1 [00:17<00:00, 17.01s/it]#015Epoch: 100%|██████████| 1/1 [00:17<00:00, 17.01s/it]\u001b[0m\n",
      "\n",
      "2024-04-10 15:31:44 Uploading - Uploading generated training model\n",
      "2024-04-10 15:32:06 Completed - Training job completed\n",
      "Training seconds: 264\n",
      "Billable seconds: 264\n"
     ]
    }
   ],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({'train': training_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Fine-tuned Sentence Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deploy the `Sentence Transformer` model using `SageMaker HuggingFaceModel` object with `inference.py` script as an entrypoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look into the `inference` script which is in the `code` directory and add the bucket name where you have the training data. Also, don't forget to update the `s3key`. This data will act as the source data, against which we will compare our target sentence. In this case, based on the description of the incident, model will find the similar accident reports.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msentence_transformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SentenceTransformer, util\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mipywidgets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m widgets\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "bucket = \u001b[33m'\u001b[39;49;00m\u001b[33msagemaker-us-east-1-827930657850\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "s3key = \u001b[33m'\u001b[39;49;00m\u001b[33msentencetransformer/input/train.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    model = SentenceTransformer(model_dir)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(data, context):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m************** input_fn *******************\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    AWS_S3_BUCKET = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mAWS_S3_BUCKET\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    AWS_ACCESS_KEY_ID = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mAWS_ACCESS_KEY_ID\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    AWS_SECRET_ACCESS_KEY = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mAWS_SECRET_ACCESS_KEY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    AWS_SESSION_TOKEN = os.getenv(\u001b[33m\"\u001b[39;49;00m\u001b[33mAWS_SESSION_TOKEN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    s3_client = boto3.client(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33ms3\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        aws_access_key_id=AWS_ACCESS_KEY_ID,\u001b[37m\u001b[39;49;00m\n",
      "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\u001b[37m\u001b[39;49;00m\n",
      "        aws_session_token=AWS_SESSION_TOKEN,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    response = s3_client.get_object(Bucket=bucket, Key=s3key)\u001b[37m\u001b[39;49;00m\n",
      "    status = response.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mResponseMetadata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, {}).get(\u001b[33m\"\u001b[39;49;00m\u001b[33mHTTPStatusCode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m status == \u001b[34m200\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mSuccessful S3 get_object response. Status - \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mstatus\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        file = pd.read_csv(response.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mBody\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), index_col=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    corpus = file[\u001b[33m'\u001b[39;49;00m\u001b[33mDescription\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].tolist()\u001b[37m\u001b[39;49;00m\n",
      "    accident_level = file[\u001b[33m'\u001b[39;49;00m\u001b[33mAccident Level\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].tolist()\u001b[37m\u001b[39;49;00m\n",
      "    critical_risk = file[\u001b[33m'\u001b[39;49;00m\u001b[33mCritical Risk\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].tolist()\u001b[37m\u001b[39;49;00m\n",
      "    genre = file[\u001b[33m'\u001b[39;49;00m\u001b[33mGenre\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].tolist()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m [corpus, accident_level, critical_risk, genre, data]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(data,model):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m************** predict_fn *******************\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    corpus, accident_level, critical_risk, genre, sentence = data\u001b[37m\u001b[39;49;00m\n",
      "    embeddings_corpus = model.encode(corpus)\u001b[37m\u001b[39;49;00m\n",
      "    embeddings = model.encode(sentence)\u001b[37m\u001b[39;49;00m\n",
      "    cosine_scores = util.pytorch_cos_sim(embeddings_corpus, embeddings)\u001b[37m\u001b[39;49;00m\n",
      "    scores = cosine_scores.tolist()\u001b[37m\u001b[39;49;00m\n",
      "    indices = \u001b[36msorted\u001b[39;49;00m(\u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(scores)), key=\u001b[34mlambda\u001b[39;49;00m i: scores[i], reverse=\u001b[34mTrue\u001b[39;49;00m)[:\u001b[34m3\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    data = {}\u001b[37m\u001b[39;49;00m\n",
      "    data[\u001b[33m'\u001b[39;49;00m\u001b[33mresult\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = []\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m indices:\u001b[37m\u001b[39;49;00m\n",
      "        data[\u001b[33m'\u001b[39;49;00m\u001b[33mresult\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].append({\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mscore\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: scores[i],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mdescription\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: corpus[i],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33maccident-level\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: accident_level[i],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mcritical-risk\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: critical_risk[i],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgenre\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: genre[i]\u001b[37m\u001b[39;49;00m\n",
      "        })\u001b[37m\u001b[39;49;00m\n",
      "    json_data = json.dumps(data)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m************** predict_fn end *******************\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m json_data\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./code/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "sentence_transformer = HuggingFaceModel(model_data = huggingface_estimator.model_data, \n",
    "                                    role = role, \n",
    "                                    source_dir = 'code',\n",
    "                                    entry_point = 'inference.py', \n",
    "                                    transformers_version='4.6',\n",
    "                                    pytorch_version='1.7',\n",
    "                                    py_version='py36',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy endpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-827930657850/huggingface-pytorch-training-2024-04-10-15-26-32-233/output/model.tar.gz), script artifact (code), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-827930657850/huggingface-pytorch-inference-2024-04-10-17-48-13-991/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2024-04-10-17-48-52-047\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-inference-2024-04-10-17-48-52-730\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-inference-2024-04-10-17-48-52-730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "predictor = sentence_transformer.deploy(initial_instance_count = 1, instance_type = 'ml.g4dn.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = predictor.predict(\"they saw the bee carton, the reaction was to move away from the box as quickly as possible to avoid the stings, they ran about 50 meters, looking for a safe area, to exit the radius of attack of the bees, but the S.S. and Breno), were attacked and consequently they suffered 02 stings, in the belly and Jehovah in the hand, verified that there was no type of allergic reaction, returned with the normal activities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': [0.9555600881576538],\n",
       "  'description': 'Project of Vazante that carried out sediment collection of current in the South of Mata target, in the drainage of Serra do Garrote. team that was composed of 04 members of the WCA company, being the S.r.s Leandro, and Jehovânio. they were moving from one collection point to another, inside a shallow drainage, they saw the bee carton, the reaction was to move away from the box as quickly as possible to avoid the stings, they ran about 50 meters, looking for a safe area, to exit the radius of attack of the bees, but the S.S. and Breno), were attacked and consequently they suffered 02 stings, in the belly and Jehovah in the hand, verified that there was no type of allergic reaction, returned with the normal activities.',\n",
       "  'accident-level': 'I',\n",
       "  'critical-risk': 'Bees',\n",
       "  'genre': 'Male'},\n",
       " {'score': [0.9555600881576538],\n",
       "  'description': 'Project of Vazante that carried out sediment collection of current in the South of Mata target, in the drainage of Serra do Garrote. team that was composed of 04 members of the WCA company, being the S.r.s Leandro, and Jehovânio. they were moving from one collection point to another, inside a shallow drainage, they saw the bee carton, the reaction was to move away from the box as quickly as possible to avoid the stings, they ran about 50 meters, looking for a safe area, to exit the radius of attack of the bees, but the S.S. and Breno), were attacked and consequently they suffered 02 stings, in the belly and Jehovah in the hand, verified that there was no type of allergic reaction, returned with the normal activities.',\n",
       "  'accident-level': 'I',\n",
       "  'critical-risk': 'Others',\n",
       "  'genre': 'Male'},\n",
       " {'score': [0.9393033981323242],\n",
       "  'description': 'On 04/04/2017, around 13: 30hs, during the current sediment activity the collaborator Warley took a bee sting in the neck, the same was using the screen, but the bee entered the bottom of the screen . After the sting the team decided to leave the workplace due to the presence of other bees. The collaborator had no reaction and continued to work normally.',\n",
       "  'accident-level': 'I',\n",
       "  'critical-risk': 'Venomous Animals',\n",
       "  'genre': 'Male'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.loads(prediction)\n",
    "result = result['result']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '308d0cf2-9a2b-4ab8-b2d3-5d3861d416ce',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '308d0cf2-9a2b-4ab8-b2d3-5d3861d416ce',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 10 Apr 2024 20:34:56 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete endpoint\n",
    "sm_client = sess.boto_session.client(\"sagemaker\")\n",
    "sm_client.delete_endpoint(EndpointName='huggingface-pytorch-inference-2024-04-10-17-48-52-730')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_input_path = \"s3://{}/{}/incident-batch.jsonl\".format(bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_output_path = \"s3://{}/{}\".format(bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_job = sentence_transformer.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    output_path=testing_output_path,\n",
    "    strategy='SingleRecord')\n",
    "\n",
    "\n",
    "batch_job.transform(\n",
    "    data=testing_input_path,\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"incident-batch.jsonl.out\"\n",
    "output_path = s3_path_join(testing_output_path,output_file)\n",
    "\n",
    "# download file\n",
    "S3Downloader.download(output_path,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(args.filepath_similar_report, args.filename_similar_report)) as f:\n",
    "    for line in f:\n",
    "        # converts jsonline array to normal array\n",
    "        line = \"[\" + line.replace(\"[\",\"\").replace(\"]\",\",\") + \"]\"\n",
    "        similar_reports = literal_eval(line)\n",
    "batch_results = similar_reports[0].split('\\\"result\\\"')[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References: \n",
    "- https://www.kaggle.com/ihmstefanini/industrial-safety-and-health-analytics-database\n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html\n",
    "- https://huggingface.co/bert-base-uncased\n",
    "- https://huggingface.co/docs/sagemaker/en/inference\n",
    "- https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
